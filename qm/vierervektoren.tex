\input{../headers/header_script.tex}
\usepackage{amsmath} 



\begin{document}

\section*{Loretz-Transformation von Vierervektoren}


Wir Betrachten einen linearen vierdimensionalen Vektoren, den sogenannten  \textbf{Minkowski-Raum}. Er besteht aus 4 komponentigen Koordinatenvektoren bzw. Vierervektoren

\begin{align}
  \label{eq:1}
  x^\mu = \begin{pmatrix}x^0\\x^1\\ x^2\\x^3 \end{pmatrix} = \begin{pmatrix}ct \\\vec x \end{pmatrix}, \qquad x^0=ct
\end{align}

bzw. in kovarianter Schreibweise

\begin{align}
  \label{eq:2}
  x_\mu = (x^0,-x^1,-x^2,-x^3) = (ct,-\vec x)
\end{align}

Aus dem Viererortsvektor lässt sich mit Hilfe des Eigenzeitdifferentials

\begin{align}
  \label{eq:7}
  d\tau = dt\sqrt{1-\frac{1}{c^2}\left(\frac{dx}{dt}\right)^2}
\end{align}

herleiten. Die Vierergeschwindigkeit \(u^\mu\) als Ableitung vom Ort nach der Eigenzeit

\begin{align}
  \label{eq:8}
  u^\mu = \frac{dx^\mu}{d\tau} = \frac{dt}{d\tau}\frac{dx^\mu}{dt}=\frac{1}{\sqrt{1-\frac{v^2}{c^2}}}\begin{pmatrix}c\\\vec v \end{pmatrix}
\end{align}

der Viererimpuls \(p^\mu\) aus dem Produkt aus der Ruhemasse \(m_0\) und der Vierergeschwindigkeit

\begin{align}
  \label{eq:9}
  p^\mu = m_0u^\mu = \frac{m_0}{\sqrt{1-\frac{v^2}{c^2}}}\begin{pmatrix}c\\\vec v \end{pmatrix} =\begin{pmatrix}mc\\\vec p \end{pmatrix}\qquad \text{mit }m= \frac{m_0}{\sqrt{1-\frac{v^2}{c^2}}}
\end{align}

Sowie der Viererkraft \(F^\mu\) als Ableitung des Viererimpuls nach der Eigenzeit

\begin{align}
  \label{eq:10}
  F^\mu = \frac{dp^\mu}{d\tau} = \frac{dt}{d\tau}\frac{dp^\mu}{dt} = \frac{1}{\sqrt{1-\frac{v^2}{c^2}}}\frac{dp^\mu}{dt} = \begin{pmatrix}c \frac{dm}{dt}\\\vec F \end{pmatrix}.
\end{align}


Um zwischen den ko- und kontra-varianten Vektoren zu wechseln, benötigt man den metrischen Tensor

\begin{align}
  \label{eq:3}
  g^{\mu\nu} = g_{\mu\nu} = \begin{pmatrix} 1&0&0&0 \\  0&-1&0&0 \\ 0&0&-1&0 \\ 0&0&0&-1  \end{pmatrix}
\end{align}


Damit gilt

\begin{align}
  \label{eq:4}
  x_{\mu} = g_{\mu\nu}x^\nu, \qquad x^\nu = g^{\nu\mu}x_\mu
\end{align}

weitere wichtige Relation

\begin{align}
  \label{eq:5}
  x^\nu = g^{\nu\mu}\underbr{x_\mu}_{\eqref{eq:4}} = g^{\nu\mu}  g_{\mu\alpha}x^\alpha = g^\nu_{\,\,\alpha}x^{\alpha}
\end{align}

Aus der Gleichung (\ref{eq:5}) folgt

\begin{align}
  \label{eq:6}
  g^\nu_{\,\,\alpha} = \begin{Bmatrix} 1,& \nu = \alpha\\ 0,&\nu\neq\alpha \end{Bmatrix} = \delta^\nu_{\alpha}
\end{align}

\subsubsection*{Wie kann man sich am besten die Ko- und Kontravarianten Vektoren vorstellen?} 

Es gibt viele unterschiedliche Vorstellungsmodelle die versuchen sich die Ko- und Kontravarianten Vektoren bildlich zu machen. Eine davon geht davon aus, dass ein kontravarianter Vektor wie ein '\textit{Stock}' ist der eine Richtung und eine Länge hat. Wobei die Länge die Größe des Vektors angibt. Einen kovarianten Vektor stellt man sich wie eine '\textit{Lasagne}' vor. Dabei ist die Größe des Vektors proportional zu der Dichte der Schichten (Lasagneplatten) in der Lasagne. D.h. je dichter die einzelnen Schichten beieinander sind desto größer ist der Wert des Vektors. Das innere Produkt zwischen den beiden Vektoren kann man sich nun bildlich vorstellen als in der Lasagne steckender Stock, dabei ist das innere Produkt proportional zu der Anzahl der Schichten die vom Stock durchstochen wurden. Wählt man bei der Lasagne eine geeignete Metrik so kann man sie in einen Stock umwandeln. Genau diese Umwandlung erledigt der Metriktensor. 

\subsubsection*{Warum macht man in karthesischen Koordinatensystemen kein Unterschied zwischen Ko- und Kontravarianten Vektoren? }

In Kartesischen Koordinatensystem ist der Metriktensor eine Einheitsmatrix d.h es gilt

\begin{align}
  \label{eq:20}
  v^i &= g^{ij}v_j \qquad\text{mit } g^{ij}=\mathds 1 \notag \\
\rightarrow v^i &= v_j 
\end{align}

Hieraus folgt dass die Unterscheidung der Hoch- und Tief- gestellten Indizies im kartesischen Koordinatensystem überflüssig ist. 

Bei der Speziellen Relativitätstheorie ist der Metriktensor immer eine kosnstante Matrix (siehe Gleichung \eqref{eq:3}. Bei der allgemeinen Relativitätstheorie ist der Metriktensor nicht mehr konstant, sondern hängt von Energie und Masse ab.


\subsection*{Lorenztransformation}

Wir betrachten zwei Inertialsysteme. Um von einem Intertialsystem IS in ein anderes IS' zu wechseln benötigt man die Loretz-Transfomations-Matritzen \(\Lambda\) mit

\begin{align}
  \label{eq:11}
  x^{'\mu}=\Lambda^\mu_{\hphantom\mu \nu}x^\nu
\end{align}

Hier bezeichnet \(x'^\mu\) ein Vierervektor im IS' Intertialsystem und \(x^\mu\) im IS Intertialsystem . Die \(\Lambda^\mu_{\,\, \nu}\) sind 4x4 Matrizen die den Zusammenhang zwischen den Inertialsystemen herstellen. Betrachten wir eine Drehung um die z-Achse, d.h IS' ist um ein Winkel \(\theta\) zu IS gedreht, dann gilt

\begin{align}
  \label{eq:12}
  \Lambda^\mu_{\,\, \nu} =
  \begin{pmatrix}
    1&0&0&0\\
0&\cos\theta&\sin\theta&0\\
0&-\sin\theta&\cos\theta&0\\
    0&0&0&1
  \end{pmatrix}
\end{align}

Ein anderer Fall wäre wenn die zwei Intertialsysteme mit einer Geschwindigkeit \(v\) zu einander sich bewegen. Dies bezeichnet man als \textbf{Boosts}. Eine Transformation für ein Boost in die z-Richtung lautet

\begin{align}
  \label{eq:13}
  \Lambda^\mu_{\,\, \nu} =
  \begin{pmatrix}
    \gamma&0&0&-\beta\gamma\\
0&1&0&0\\
0&0&1&0\\
    -\beta\gamma&0&0&\gamma
  \end{pmatrix}
\end{align}

mit den Abkürzungen

\begin{align}
  \label{eq:14}
  \beta =\frac{|\vec v|}{c}= \frac{v}{c} ,\qquad \gamma = \frac{1}{\sqrt{1-\frac{v^2}{c^2}}}
\end{align}


Für dieses Beispiel angewandt ergibt sich im IS' für die einzelnen Komponenten \(x'^\mu\)

\begin{align}
  \label{eq:15}
  x'^\mu =
  \begin{pmatrix}
     \gamma(x^0-\beta x^3)\\
     x^1\\
     x^2\\
 \gamma(x^3-vt)
  \end{pmatrix}
\end{align}

Eine Lorentztransformation ist eine Transformation die die Länge \(x^2\)  des Vektors \(x^\mu\) unverändert lässt. Zum Beweis

\begin{align}
  \label{eq:16}
  (x')^2 &= x'_\nu x'^\nu = \underbr{ g_{\mu\nu}x^{'\mu}}_{~(\ref{eq:4})}x^{'\nu} \notag \\
&=  g_{\mu\nu}\underbr{ x^{'\mu}}_{\Lambda^\mu_{\,\, \rho}x^\rho}\cdot \underbr{ x^{'\nu}}_{\Lambda^\nu_{\,\, \sigma}x^\sigma} \notag \\
 &= \underbrace{\Lambda^\mu_{\,\, \rho}  \Lambda^\nu_{\,\, \sigma}g_{\mu\nu}}_{g_{\rho\sigma}}x^\rho x^\sigma\notag \\
&= g_{\sigma\rho} x^\rho x^\sigma  = x_\sigma x^\sigma = x^2
\end{align}

Aus der Gleichung (\ref{eq:16})  folgt  \((x')^2 = x^2\) und d.h. dass die relative Länge in beiden Inertialsystemen erhalten ist. \(x^2\) ist Lorentz-Invariant. 


Da die Lorenztransformation die Länge eines Vektors unverändert lässt, also eine unitäre Transformation ist, gilt die allgemeine Eigenschaft


\begin{align}
  \label{eq:22}
  \Lambda^{-1}\Lambda=\mathds 1_4
\end{align}

Wir möchten nun die Umkehrmatrix  \(\Lambda^{-1}\) berechnen. Wir gehen von Gleichung \eqref{eq:11} aus die nochmal lautet

\begin{align}
  \label{eq:21}
 \Lambda^{-1}\cdot|\qquad   x'^{\mu} &= \Lambda^{\mu}_{\hphantom \mu \nu}x^\nu \notag\\
 \Lambda^{-1}  x'^{\mu} &= \underbrace{ \Lambda^{-1}\Lambda^{\mu}_{\hphantom \mu \nu}}_{\mathds 1}x^\nu 
\end{align}

Aufgrund der Beziehung \eqref{eq:22} formen wir diese Gleichung um ohne zunächst zu wissen, was das Objekt \(\Lambda^{-1}\) in der Indexschreibweise bedeutet

\begin{align}
  \label{eq:23}
  x^{\nu} = \Lambda^{-1}x'^{\mu}
\end{align}

Desweiteren gehen wir davon aus, dass das Skalarprodukt in allen Inertialsystemen erhalten ist. Somit gilt

\begin{align}
  \label{eq:24}
  x^\nu x_\nu &= x'^{\mu}x'_{\mu} \qquad\text{mit } x^{\nu} = \Lambda^{-1}x'^{\mu}\notag\\
\Lambda^{-1}x'^{\mu} x_\nu &= x'^{\mu}x'_{\mu}
\end{align}

Nun möchten wir herausfinden wie sich der kovariante Vektor \(x'_{\mu}\) transformiert

\begin{align}
  \label{eq:25}
  x'_{\mu} = g_{\mu\alpha} x'^\alpha 
  = g_{\mu\alpha}\underbrace{ \Lambda^{\alpha}_{\hphantom\alpha \beta}
    \,x^\beta}_{\eqref{eq:11}} 
  =\underbrace{ g_{\mu\alpha}\Lambda^{\alpha}_{\hphantom\alpha\beta}\,
    g^{\beta\nu}}_{\Lambda^{\hphantom \mu \nu}_{\mu}}x_{\nu}
\end{align}
Somit Transformiert sich ein kovarianter Vektor

\begin{align}
  \label{eq:26}
   \boxed{x'_{\mu} = \Lambda^{\hphantom \mu \nu}_{\mu}x_{\nu}}
\end{align}

mit 
\begin{align}
  \label{eq:27}
  \Lambda^{\hphantom \mu \nu}_{\mu} 
  = g_{\mu\alpha}\Lambda^{\alpha}_{\hphantom\alpha \beta}\,g^{\beta\nu}
\end{align}

Setzen wir nun die Gleichung \eqref{eq:26} in \eqref{eq:24} ein so folgt

\begin{align}
  \label{eq:28}
  \Lambda^{-1}x'^{\mu} x_\nu &= x'^{\mu}x'_{\mu} 
  \qquad\text{mit } x'_{\mu} = \Lambda^{\hphantom \mu \nu}_{\mu}x_{\nu} \notag \\
 \Lambda^{-1}\cancel{x^{'\mu}}\cancel{ x_\nu} &= \cancel{x'^{\mu}}\Lambda^{\hphantom \mu \nu}_{\mu}\cancel{x_{\nu}} \notag \\
\end{align}

Aus \eqref{eq:28} folgt dass die Inverse Matrix von \(\Lambda\) mit

\begin{align}
  \label{eq:29}
   \boxed{ \Lambda^{-1} = \Lambda^{\hphantom \mu \nu}_{\mu} = g_{\mu\alpha}\Lambda^{\alpha}_{\hphantom\alpha \beta}g^{\beta\nu} }
\end{align}


Für unitäre Matrizen könen wir die Beziehung  \eqref{eq:22} nun in der Tensorschreibweise ausdrücken

\begin{align}
  \label{eq:17}
 \boxed{ \Lambda_\mu^{\,\, \rho}\Lambda^\mu_{\,\,\sigma} = g^\rho_{\,\,\sigma} =
   \delta^\rho_{\,\, \sigma} }
\end{align}

Wir wollen noch die Umkehrmatrix \(\Lambda^{-1}\) für die Transformationmatrix
\eqref{eq:13} bestimmen. Die Matrix lautet

\begin{equation}
  \label{eq:18}
    \Lambda^\mu_{\hphantom\mu \nu} =
  \begin{pmatrix}
    \gamma&0&0&-\beta\gamma\\
    0&1&0&0\\
    0&0&1&0\\
    -\beta\gamma&0&0&\gamma
  \end{pmatrix}
\end{equation}

Dabei steht der \emph{linke Index} von \(\Lambda\) für die \emph{Zeilen} und
der \emph{rechte Index} für die \emph{Spalten} also wie auch bei einer
``gewöhnlichen'' Matrix. Es spielt keine Rolle ob der linke Index Oben oder
Unten ist, er steht immer für Zeilen. Genauso spielt es keine Rolle ob der rechte
Index Oben oder Unten steht, er steht immer für Spalten.

Um nun die Umkehrmatrix von \eqref{eq:18} zu bestimmen (siehe \eqref{eq:29})
müssen wir den Zeilenindex der in \eqref{eq:18} kontravariant ist, in eine
kovariante Form bringen, d.h. wir müssen die Zeilenvektoren in \eqref{eq:18} von
der kontravarianter Form in die kovariante Form bringen. Dies erreichen wir in
dem wir die einzelnen Zeilenvektoren mit dem Metriktensor \(g_{\mu \alpha}\)
multiplizieren. D.h. die erste Komponente der einzelnen Zeilenvektoren
übernehmen und alle weiteren mit \(-1\) multiplizieren. Dies sieht dann wie
folgt aus
\begin{equation}
  \label{eq:19}
     g_{\mu\alpha}\Lambda^\alpha_{\hphantom\alpha \nu} =
     \Lambda_{\mu \nu} =
  \begin{pmatrix}
    \gamma&0&0&\beta\gamma\\
    0&-1&0&0\\
    0&0&-1&0\\
    -\beta\gamma&0&0&-\gamma
  \end{pmatrix}
\end{equation}

Als nächstes müssen wir den Spaltenindex der in \eqref{eq:19} bzw. \eqref{eq:19} kovariant ist, in
eine kontravariante Form bringen. Dazu multiplizieren wir \eqref{eq:19} mit dem
Metriktensor \(g^{\beta\nu}\) d.h. wir übernehmen bei den Spaltenvektoren in
\eqref{eq:19} die erste Komponente und multiplizieren alle weitere Komponente
mit \(-1\). Wir erhalten:
\begin{equation}
  \label{eq:30}
   \Lambda_{\mu \beta}\,g^{\beta\nu} =  \Lambda_{\mu}^{\hphantom \mu \nu}=
  \begin{pmatrix}
    \gamma&0&0&\beta\gamma\\
    0&1&0&0\\
    0&0&1&0\\
    \beta\gamma&0&0&\gamma
  \end{pmatrix}
\end{equation}

Aus \eqref{eq:30} folgt direkt die Umkehrmatrix von \eqref{eq:18} mit

\begin{equation}
  \label{eq:31}
   \left(\Lambda^\mu_{\hphantom\mu \nu}\right)^{-1} 
   = \Lambda_{\mu}^{\hphantom \mu \nu}=
  \begin{pmatrix}
    \gamma&0&0&\beta\gamma\\
    0&1&0&0\\
    0&0&1&0\\
    \beta\gamma&0&0&\gamma
  \end{pmatrix}
\end{equation}

Eine weitere Möglichkeit die Umkehrmatrix von \eqref{eq:18} zu bestimmen ist
wenn wir folgende Bedingung betrachten:
\begin{equation}
  \label{eq:32}
  \Lambda(-v) = \Lambda(v)^{-1}
\end{equation}

D.h. ``grob gesagt'' dass das gestrichelte System jetzt das nicht gestrichelte
ist und dass das nicht gestrichelte jetzt das gestrichelte ist. Mit \(\Lambda\)
aus \eqref{eq:18}

\begin{align}
  \label{eq:33}
   \Lambda(v) &=
  \begin{pmatrix}
    \gamma&0&0&-\beta\gamma\\
    0&1&0&0\\
    0&0&1&0\\
    -\beta\gamma&0&0&\gamma
  \end{pmatrix}
  \quad\text{mit }
  \beta = \frac{v}{c}\quad\text{und }
  \gamma = \frac{1}{\sqrt{1-\frac{v^2}{c^2}}}\notag\\
   &=
  \begin{pmatrix}
    \frac{1}{\sqrt{1-\frac{v^2}{c^2}}}&0&0&-\frac{v}{c\sqrt{1-\frac{v^2}{c^2}}}\\
    0&1&0&0\\
    0&0&1&0\\
    -\frac{v}{c\sqrt{1-\frac{v^2}{c^2}}}&0&0&\frac{1}{\sqrt{1-\frac{v^2}{c^2}}}
  \end{pmatrix}
\end{align}

Substituieren wir nun in \eqref{eq:33} \(v\) durch \(-v\), so erhalten wir:
\begin{equation}
  \label{eq:34}
  \Lambda(-v)=
   \begin{pmatrix}
    \frac{1}{\sqrt{1-\frac{v^2}{c^2}}}&0&0&\frac{v}{c\sqrt{1-\frac{v^2}{c^2}}}\\
    0&1&0&0\\
    0&0&1&0\\
    \frac{v}{c\sqrt{1-\frac{v^2}{c^2}}}&0&0&\frac{1}{\sqrt{1-\frac{v^2}{c^2}}}
  \end{pmatrix}
\end{equation}

Drücken wir \eqref{eq:34} wieder durch \(\beta\) und \(\gamma\) aus, so folgt:
\begin{equation}
  \label{eq:35} 
   \Lambda(-v)=
  \begin{pmatrix}
    \gamma&0&0&\beta\gamma\\
    0&1&0&0\\
    0&0&1&0\\
    \beta\gamma&0&0&\gamma
  \end{pmatrix}\stackrel{\eqref{eq:32}}=\Lambda(v)^{-1}
\end{equation}

In \eqref{eq:35} erhalten wir also die gleiche Umkehrmatrix wie schon in
\eqref{eq:31}. D.h. beide Vorgehensweisen sind äquivalent.


\subsection*{Referenzen}
\begin{itemize}
\item Wachter: Relativistische Quantenmechanik
\item \url{http://www.tphys.physik.uni-tuebingen.de/muether/quanten/qms9.ps}
\item \url{http://www.rpi.edu/dept/phys/Courses/PHYS4210/S10/NotesOnVectors.pdf}
\end{itemize}

\end{document}
